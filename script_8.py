# Ethical Considerations and Privacy Protection
print("="*70)
print("ETHICAL CONSIDERATIONS AND PRIVACY PROTECTION")
print("="*70)

ethical_framework = """
ETHICAL FRAMEWORK FOR CHURN PREDICTION SYSTEM

1. PRIVACY PROTECTION MEASURES
   
   a) Data Minimization
      ‚Ä¢ Collect only necessary data for churn prediction
      ‚Ä¢ Regular data audits to remove unused information
      ‚Ä¢ Automated data retention policies
   
   b) Data Anonymization
      ‚Ä¢ Remove personally identifiable information (PII)
      ‚Ä¢ Use pseudonymization techniques
      ‚Ä¢ Implement k-anonymity standards
   
   c) Consent Management
      ‚Ä¢ Explicit consent for data usage
      ‚Ä¢ Granular consent options
      ‚Ä¢ Easy opt-out mechanisms
      ‚Ä¢ Regular consent renewals

2. BIAS MITIGATION STRATEGIES
   
   a) Algorithmic Fairness
      ‚Ä¢ Regular bias testing across demographic groups
      ‚Ä¢ Fairness-aware machine learning techniques
      ‚Ä¢ Diverse training data representation
   
   b) Protected Attribute Analysis
      ‚Ä¢ Monitor for discrimination based on:
        - Age (Senior Citizen status)
        - Gender
        - Marital Status
        - Geographic location
   
   c) Fairness Metrics
      ‚Ä¢ Demographic parity
      ‚Ä¢ Equalized odds
      ‚Ä¢ Individual fairness measures

3. TRANSPARENCY AND EXPLAINABILITY
   
   a) Model Interpretability
      ‚Ä¢ Feature importance explanations
      ‚Ä¢ Decision reasoning for high-risk predictions
      ‚Ä¢ Clear documentation of model limitations
   
   b) Customer Rights
      ‚Ä¢ Right to explanation for automated decisions
      ‚Ä¢ Right to human review
      ‚Ä¢ Right to appeal predictions
   
   c) Stakeholder Communication
      ‚Ä¢ Regular fairness reports
      ‚Ä¢ Clear privacy policies
      ‚Ä¢ Transparent data usage explanations

4. GOVERNANCE AND COMPLIANCE
   
   a) Regulatory Compliance
      ‚Ä¢ GDPR compliance for EU customers
      ‚Ä¢ CCPA compliance for California customers
      ‚Ä¢ Banking regulation adherence
   
   b) Ethics Committee
      ‚Ä¢ Regular ethics reviews
      ‚Ä¢ Diverse committee composition
      ‚Ä¢ External ethics audits
   
   c) Risk Management
      ‚Ä¢ Continuous monitoring
      ‚Ä¢ Incident response procedures
      ‚Ä¢ Regular security assessments
"""

print(ethical_framework)

# Bias Analysis
print("\n" + "="*50)
print("BIAS ANALYSIS ON CURRENT MODEL")
print("="*50)

# Analyze potential bias in the model predictions
def analyze_bias(df, model, scaler, label_encoders, feature_columns):
    """Analyze model for potential bias across protected attributes"""
    
    # Prepare features for prediction
    X_analysis = df[feature_columns].copy()
    
    # Encode categorical variables
    for col in label_encoders:
        if col in X_analysis.columns:
            try:
                X_analysis[col] = label_encoders[col].transform(X_analysis[col].astype(str))
            except:
                X_analysis[col] = 0
    
    # Handle missing values
    X_analysis = X_analysis.fillna(X_analysis.median())
    
    # Scale features and predict
    X_scaled = scaler.transform(X_analysis)
    predictions = model.predict_proba(X_scaled)[:, 1]
    
    # Add predictions to dataframe
    df_analysis = df.copy()
    df_analysis['Predicted_Churn_Prob'] = predictions
    df_analysis['Actual_Churn'] = (df['Churn'] == 'Yes').astype(int)
    
    print("1. Gender Bias Analysis:")
    gender_analysis = df_analysis.groupby('Gender').agg({
        'Predicted_Churn_Prob': 'mean',
        'Actual_Churn': 'mean'
    }).round(4)
    print(gender_analysis)
    
    print("\n2. Age Bias Analysis:")
    age_analysis = df_analysis.groupby('Senior Citizen').agg({
        'Predicted_Churn_Prob': 'mean',
        'Actual_Churn': 'mean'
    }).round(4)
    age_analysis.index = ['Non-Senior', 'Senior']
    print(age_analysis)
    
    print("\n3. Marital Status Bias Analysis:")
    marital_analysis = df_analysis.groupby('Marital Status').agg({
        'Predicted_Churn_Prob': 'mean',
        'Actual_Churn': 'mean'
    }).round(4)
    print(marital_analysis)
    
    # Calculate fairness metrics
    print("\n4. Fairness Metrics:")
    
    # Demographic Parity (difference in positive prediction rates)
    male_pred_rate = (df_analysis[df_analysis['Gender'] == 'Male']['Predicted_Churn_Prob'] > 0.5).mean()
    female_pred_rate = (df_analysis[df_analysis['Gender'] == 'Female']['Predicted_Churn_Prob'] > 0.5).mean()
    demographic_parity_diff = abs(male_pred_rate - female_pred_rate)
    
    print(f"   Demographic Parity Difference (Gender): {demographic_parity_diff:.4f}")
    print(f"   {'‚úÖ FAIR' if demographic_parity_diff < 0.1 else '‚ö†Ô∏è POTENTIAL BIAS'} (threshold: 0.1)")
    
    # Similar analysis for age
    senior_pred_rate = (df_analysis[df_analysis['Senior Citizen'] == 1]['Predicted_Churn_Prob'] > 0.5).mean()
    non_senior_pred_rate = (df_analysis[df_analysis['Senior Citizen'] == 0]['Predicted_Churn_Prob'] > 0.5).mean()
    age_parity_diff = abs(senior_pred_rate - non_senior_pred_rate)
    
    print(f"   Demographic Parity Difference (Age): {age_parity_diff:.4f}")
    print(f"   {'‚úÖ FAIR' if age_parity_diff < 0.1 else '‚ö†Ô∏è POTENTIAL BIAS'} (threshold: 0.1)")
    
    return {
        'gender_bias': demographic_parity_diff,
        'age_bias': age_parity_diff,
        'bias_detected': demographic_parity_diff > 0.1 or age_parity_diff > 0.1
    }

# Perform bias analysis
bias_results = analyze_bias(df_processed, model_data['best_model'], 
                          model_data['scaler'], model_data['label_encoders'], 
                          model_data['feature_columns'])

print(f"\n5. Overall Bias Assessment:")
print(f"   Gender Bias Score: {bias_results['gender_bias']:.4f}")
print(f"   Age Bias Score: {bias_results['age_bias']:.4f}")
print(f"   {'‚ö†Ô∏è BIAS DETECTED - Recommend additional fairness measures' if bias_results['bias_detected'] else '‚úÖ NO SIGNIFICANT BIAS DETECTED'}")

# Privacy protection implementation
privacy_measures = """
PRIVACY PROTECTION IMPLEMENTATION

1. DATA PSEUDONYMIZATION
   ‚Ä¢ Replace customer IDs with pseudonyms
   ‚Ä¢ Hash sensitive identifiers
   ‚Ä¢ Separate identity mapping

2. DIFFERENTIAL PRIVACY
   ‚Ä¢ Add statistical noise to aggregate queries
   ‚Ä¢ Protect individual privacy in analytics
   ‚Ä¢ Maintain model utility

3. SECURE DATA HANDLING
   ‚Ä¢ End-to-end encryption
   ‚Ä¢ Secure key management
   ‚Ä¢ Access logging and monitoring

4. DATA LIFECYCLE MANAGEMENT
   ‚Ä¢ Automated data expiration
   ‚Ä¢ Secure data deletion
   ‚Ä¢ Audit trail maintenance
"""

print("\n" + "="*50)
print("PRIVACY PROTECTION MEASURES")
print("="*50)
print(privacy_measures)

print("\n‚úÖ Ethical framework and privacy measures documented!")
print("üìã Ready for stakeholder review and implementation")